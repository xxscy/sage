# RAG COT Chain 深层推理指导设计总结

## 📋 概述

`rag_cot_chain.py` 通过多层次的深层推理指导，帮助 LLM 在判断是否需要调用 `human_interaction_tool` 时，优先使用推理和常识，而不是直接求助用户。设计体现在两个关键 prompt 中：

1. **`build_cot_prompt`** - 最终决策阶段的深层推理指导
2. **`build_chain_planner_prompt`** - 规划阶段的深层推理指导

---

## 🎯 设计方面

### 1. **情境上下文分析 (Situational Context Analysis)**

**位置**: `build_cot_prompt` (509-512行)

**设计要点**:
- 要求 LLM 分析命令背后的情境，而非仅看表面文字
- 提供具体示例说明如何从情境推断意图：
  - 来电时调整音量 → 推断为"降低音量"（而非提高）
  - "太亮了" → 推断为"调暗"（而非调亮）
  - "准备睡觉" → 推断为"调暗/关闭灯光"

**目的**: 让系统理解用户的实际场景，而非机械解析命令

---

### 2. **常识推理 (Common Sense Reasoning)**

**位置**: `build_cot_prompt` (514-518行)

**设计要点**:
- 建立常识规则库，覆盖常见场景：
  - 来电时"调整音量" → 通常指"降低"
  - "太亮/太冷/太吵" → 用户想要相反效果
  - "准备睡觉" → 需要更暗、更安静的环境
  - "合适的模式"用于油腻餐具 → 通常指"强力清洗模式"

**目的**: 将日常逻辑编码到 prompt 中，减少不必要的澄清

---

### 3. **默认动作推断 (Default Action Inference)**

**位置**: `build_cot_prompt` (520-523行)

**设计要点**:
- 当意图明确但具体数值缺失时，提供合理的默认值：
  - "调整音量"（来电时）→ 降低50%或静音
  - "设置合适模式"（油腻餐具）→ 强力清洗模式
  - "太亮" → 调暗到舒适水平（30-50%当前亮度）

**目的**: 在信息不完整时仍能执行合理操作，而非直接求助

---

### 4. **上下文消歧 (Contextual Disambiguation)**

**位置**: `build_cot_prompt` (525-527行)

**设计要点**:
- 利用上下文信息解决指代模糊：
  - "关闭它" + TV正在播放 → 推断为关闭TV
  - "那个游戏" + 用户刚看体育 → 推断为同一体育项目

**目的**: 通过上下文而非询问用户来解决指代问题

---

### 5. **增强置信度启发式规则 (Enhanced Confidence Heuristics)**

**位置**: `build_cot_prompt` (542-549行)

**设计要点**:
包含7种启发式规则：

1. **情境推断**: 命令提及情境（来电、睡觉、太亮/冷/吵）→ 基于常识推断明显动作
2. **方向推断**: 命令指定方向（调整、改变、设置）但无具体值 → 从上下文推断方向
3. **默认值推断**: 方向明确但值缺失 → 使用合理默认值
4. **设备消歧**: 设备查找返回单一高匹配 → 视为目标设备
5. **偏好映射**: 将主观术语映射到用户偏好（如有）或通用默认值
6. **环境抱怨**: 假设明显的纠正动作（太亮→调暗，太吵→降低音量）
7. **状态查询**: 直接从设备状态回答，无需偏好信息

**目的**: 提供系统化的推理路径，提高决策置信度

---

### 6. **明确的使用/不使用场景指导**

**位置**: `build_cot_prompt` (529-540行)

#### **使用 `human_interaction_tool` 的场景**:
1. 模糊指代：代词（"it", "this", "that"）无法通过深层推理和上下文解决
2. 缺失个性化信息：关键用户偏好缺失且无法从常识推断
3. 非标准表达：真正无法理解的俚语或创意表达
4. 多重有效解释：命令确实有多种合理含义且无法通过上下文区分

#### **不使用 `human_interaction_tool` 的场景**:
1. 命令明确且提供所有必要细节
2. 常识和情境上下文允许推断意图
3. 可以基于情境应用合理默认值
4. 上下文（设备状态、最近交互、情境线索）可以消歧
5. 缺失信息是具体值，但方向/意图明确

**目的**: 明确边界，避免过度或不足使用澄清工具

---

### 7. **强自主性偏向 (Strong Autonomy Bias)**

**位置**: `build_cot_prompt` (551行)

**设计要点**:
```
Your STRONG bias should be to solve the command autonomously using deep reasoning 
and common sense. Only ask for clarification when there is a genuine, unresolvable 
ambiguity that prevents action.
```

**目的**: 明确系统应优先自主解决，澄清是最后手段

---

### 8. **结构化推理步骤 (Structured Reasoning Steps)**

**位置**: `build_cot_prompt` (571-583行)

**设计要点**:
要求 LLM 按5步进行推理：

1. **表面分析**: 识别关键词、动词、名词、形容词、代词、显式参数
2. **深层意图推断**: 
   - 考虑：用户环境中发生了什么？
   - 推断：在这种情况下什么动作合理？
   - 应用：关于用户可能想要什么的常识推理
3. **信息缺口分析**: 识别缺失信息，判断是否可通过：
   - 常识推断
   - 情境上下文
   - 合理默认值
   - 检索到的偏好/历史
4. **模糊性解决**: 确定剩余模糊性是否真正阻碍执行
5. **决策**: 决定是否调用工具，默认倾向"不需要"（当深层推理和常识可以解决时）

**目的**: 强制 LLM 进行系统性思考，而非跳跃式结论

---

### 9. **规划阶段的深层推理优先 (Deep Reasoning First in Planning)**

**位置**: `build_chain_planner_prompt` (647-652行)

**设计要点**:
在规划阶段就强调深层推理优先：

```
IMPORTANT: Deep Reasoning First
Before requesting additional information, apply deep reasoning about the user's situation and intent:
- Analyze the situational context: What is happening?
- Infer the underlying intent: What does the user really want?
- Apply common sense: Use everyday logic to fill gaps
- Only retrieve information that is truly needed and cannot be inferred
```

**目的**: 在检索信息前先推理，避免不必要的工具调用

---

### 10. **效率与置信度指导原则 (Confidence & Efficiency Guidelines)**

**位置**: `build_chain_planner_prompt` (654-660行)

**设计要点**:
- **推理优先于检索**: 在请求更多信息前应用深层推理和常识
- **情境推断**: 如果命令提及情境，先推断明显动作
- **偏好单次决定性检索**: 一旦工具提供清晰数据，重用而非重复查找
- **避免冗余查询**: 不要询问可通过上下文或常识推断的信息
- **快速进入最终决策**: 一旦意图可用现有证据或推断满足，立即进入决策
- **自主性优于澄清**: 目标是保持助手自主性，将澄清视为最后手段

**目的**: 优化工具使用效率，减少不必要的检索循环

---

## 🔄 设计层次

### 第一层：规划阶段 (`build_chain_planner_prompt`)
- **目标**: 在检索信息前先推理
- **重点**: 避免不必要的工具调用
- **策略**: "推理优先于检索"

### 第二层：决策阶段 (`build_cot_prompt`)
- **目标**: 基于已检索信息进行深层推理
- **重点**: 最大化自主解决能力
- **策略**: "常识和情境推断优先于澄清"

---

## 💡 核心设计理念

1. **自主性优先**: 系统应尽可能自主解决，而非频繁求助用户
2. **常识推理**: 将日常逻辑编码到 prompt 中，而非仅依赖检索
3. **情境理解**: 理解用户的实际场景，而非机械解析命令
4. **渐进式推理**: 从表面分析到深层推断，系统性思考
5. **明确边界**: 清楚定义何时需要澄清，何时可以推断

---

## 📊 设计效果

通过这些设计，系统能够：
- ✅ 理解情境隐含的意图（如"来电时调整音量"→降低音量）
- ✅ 应用常识推理填补信息缺口
- ✅ 使用合理默认值而非直接求助
- ✅ 通过上下文消歧而非询问用户
- ✅ 减少不必要的 `human_interaction_tool` 调用
- ✅ 提高智能家居助手的自主性和用户体验


